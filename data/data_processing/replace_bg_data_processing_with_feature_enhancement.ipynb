{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **REPLACE-BG DATA PROCESSING**   \n",
    "- **With feature enhancement**  \n",
    "  - 5 minute change\n",
    "  - 30 minute change\n",
    "  - 60 minute change\n",
    "  - 60 minute moving average\n",
    "  - 60 minute standard deviation\n",
    "  - 60 minute largest increase\n",
    "  - 60 minute largest decrease\n",
    "  - 360 minute moving average\n",
    "  - 360 minute standard deviation\n",
    "  \n",
    "- **2:1:2 hypo:eu:hyper sampling ratio**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CONTENTS**\n",
    "\n",
    "[1. Requirements & Environment](#1-requirements--environment)  \n",
    "[2. Read in Replace-BG Dataset](#2-read-in-replace-bg-dataset)  \n",
    "[3. Initial Processing & Train/Validation/Test Split](#3-initial-processing--trainvalidationtest-split)  \n",
    "[4. Training Data Processing](#4-training-data-processing)  \n",
    "[5. Validation Data Processing](#5-validation-data-processing)  \n",
    "[6. Test Data Processing](#6-test-data-processing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Requirements & Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_processing_modules import *\n",
    "from data_processing_parameters import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Read in Replace-BG Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Using a relative path from current working directory\n",
    "replace_bg_path = os.path.join('..', 'source_data', 'SourceData', 'ReplaceBG', 'Data_tables', 'hdevicecgm.txt')\n",
    "\n",
    "# Read the data\n",
    "replace_cgm_data = pd.read_csv(replace_bg_path, delimiter='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.    ReplaceBG Initial Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes calibration data / direct blood glucose measurements from dataset leaving only CGM data\n",
    "replace_cgm_data = replace_cgm_data[replace_cgm_data['RecordType'] == 'CGM']\n",
    "\n",
    "# Drop columns that will not be required\n",
    "replace_cgm_data = replace_cgm_data.drop(columns=['RecID', 'ParentHDeviceUploadsID', 'SiteID', 'DexInternalDtTmDaysFromEnroll', 'DexInternalTm', 'RecordType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by ptid, then devicedttmdaysfromenroll then devicetm to separate the data into individual patient time series sequences\n",
    "replace_cgm_data = replace_cgm_data.sort_values(by=['PtID', 'DeviceDtTmDaysFromEnroll', 'DeviceTm']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the DeviceDtTmDaysFromEnroll to the base date\n",
    "# base date imported from data_processing_parameters.py\n",
    "replace_cgm_data['DateTime'] = base_date + pd.to_timedelta(replace_cgm_data['DeviceDtTmDaysFromEnroll'], unit='D')\n",
    "\n",
    "# add device time to the date time to get a full datetime stamp\n",
    "replace_cgm_data['DateTime'] = replace_cgm_data['DateTime'] + pd.to_timedelta(replace_cgm_data['DeviceTm'])\n",
    "\n",
    "# Drop DeviceDtTmDaysFromEnroll column as no longer needed\n",
    "replace_cgm_data = replace_cgm_data.drop(columns=['DeviceDtTmDaysFromEnroll'])\n",
    "\n",
    "# Ensure Data is still sorted by Patient ID and DateTime\n",
    "replace_cgm_data = replace_cgm_data.sort_values(by=['PtID', 'DateTime'], ascending= [True, True])\n",
    "\n",
    "# Drop DeviceTm column as no longer needed\n",
    "replace_cgm_data = replace_cgm_data.drop(columns=['DeviceTm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate replace_cgm into individual patient time series dfs\n",
    "replace_cgm_data_dict = separate_ptid_data(replace_cgm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardises the earliest date for each patient\n",
    "replace_cgm_data_dict = align_start_date(replace_cgm_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation and test datasets for each patient maintaining the time series order\n",
    "replace_cgm_training_data = {}\n",
    "replace_cgm_validation_data = {}\n",
    "replace_cgm_test_data = {}\n",
    "\n",
    "for ptid, df in replace_cgm_data_dict.items():\n",
    "    train, test = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "    train, val = train_test_split(train, test_size=0.1, shuffle=False)\n",
    "    replace_cgm_training_data[ptid] = train\n",
    "    replace_cgm_validation_data[ptid] = val\n",
    "    replace_cgm_test_data[ptid] = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.    ReplaceBG Training Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate data points for single missing values\n",
    "# add engineered features\n",
    "for ptid, df in replace_cgm_training_data.items():\n",
    "    df = df.copy()\n",
    "    df['real_value_flag'] = 1\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "\n",
    "    # Identify rows where TimeDiff is around 600 seconds (10 min)\n",
    "    mask = (df['TimeDiff'] > 595) & (df['TimeDiff'] < 605)\n",
    "    insert_rows = df[mask].copy()\n",
    "\n",
    "    if not insert_rows.empty:\n",
    "        # Modify new rows: set `real_value_flag = 0`, shift `DateTime`, and set `GlucoseValue = NaN`\n",
    "        insert_rows['real_value_flag'] = 0\n",
    "        insert_rows['DateTime'] -= pd.to_timedelta(5, unit='m')\n",
    "        insert_rows['GlucoseValue'] = np.nan\n",
    "\n",
    "        # Append new rows to the dataframe and sort\n",
    "    df = pd.concat([df, insert_rows]).sort_values(by='DateTime').reset_index(drop=True)\n",
    "\n",
    "    # Linearly interpolate the glucose value\n",
    "    df['GlucoseValue'] = df['GlucoseValue'].interpolate(method='linear')\n",
    "\n",
    "    # Add engineered features        \n",
    "    df['5min_change'] = df['GlucoseValue'].diff(1)\n",
    "    df['30min_change'] = df['GlucoseValue'].diff(6)\n",
    "    df['1hr_change'] = df['GlucoseValue'].diff(12)\n",
    "\n",
    "    df['1hr_mov_avg'] = df['GlucoseValue'].rolling(window=12).mean()\n",
    "    df['1hr_mov_std'] = df['GlucoseValue'].rolling(window=12).std()\n",
    "\n",
    "    df['1hr_largest_increase'] = df['5min_change'].rolling(window=12).max()\n",
    "    df['1hr_largest_decrease'] = df['5min_change'].rolling(window=12).min()\n",
    "\n",
    "    df['6hr_mov_avg'] = df['GlucoseValue'].rolling(window=72).mean()\n",
    "    df['6hr_mov_std'] = df['GlucoseValue'].rolling(window=72).std()\n",
    "\n",
    "    # create hour and minute columns~\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    # creates a rolling sum to determins complete data sequences suitable for use\n",
    "    # data sequences that hold missing data over  gaps greater that 10 minutes 5 seconds will be excluded\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "    df['TimeDiffFlag'] = df['TimeDiff'].apply(lambda x: 0 if x < 295 or x > 305 else 1)\n",
    "    df['RollingTimeDiffFlag'] = df['TimeDiffFlag'].rolling(window=slice_size).sum()\n",
    "\n",
    "    # drop columns\n",
    "    df = df.drop(columns=['DateTime', 'TimeDiff', 'TimeDiffFlag', 'real_value_flag'])\n",
    "\n",
    "    # replace the initial df with the new df\n",
    "    replace_cgm_training_data[ptid] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create slices of total input length\n",
    "\n",
    "replace_training_slices = []\n",
    "\n",
    "for ptid, df in replace_cgm_training_data.items():\n",
    "    rolling_flag_array = df[\"RollingTimeDiffFlag\"].to_numpy()  # Convert to NumPy array for fast indexing\n",
    "    num_rows = len(df)\n",
    "    starting_index = 0\n",
    "\n",
    "    while starting_index + slice_size <= num_rows:\n",
    "        if rolling_flag_array[starting_index + slice_size - 1] == slice_size:  # Use precomputed array\n",
    "            replace_training_slices.append(df.iloc[starting_index:starting_index + slice_size])\n",
    "            starting_index += overlap  # Move by overlap\n",
    "        else:\n",
    "            starting_index += 1  # Ensure progress to avoid infinite loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143709, 1242100, 975918)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo_training_slices = []\n",
    "eu_training_slices = []\n",
    "hyper_training_slices = []\n",
    "\n",
    "for slice in replace_training_slices:\n",
    "\n",
    "    target_glucose_values = slice.iloc[-24:]['GlucoseValue'].values\n",
    "\n",
    "    hypo_value_count = np.sum(target_glucose_values < 70)\n",
    "    eu_value_count = np.sum((target_glucose_values >= 70) & (target_glucose_values <= 180))\n",
    "    hyper_value_count = np.sum(target_glucose_values > 180)\n",
    "\n",
    "    min_points = 6\n",
    "\n",
    "    if hypo_value_count >= min_points:\n",
    "        hypo_training_slices.append(slice)\n",
    "    elif hyper_value_count >= min_points:\n",
    "        hyper_training_slices.append(slice)\n",
    "    else:\n",
    "        eu_training_slices.append(slice)\n",
    "\n",
    "\n",
    "len(hypo_training_slices), len(eu_training_slices), len(hyper_training_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21349, 22009, 22506, 44330)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_030_slices = []\n",
    "_3060_slices = []\n",
    "_6090_slices = []\n",
    "_90120_slices = []\n",
    "\n",
    "for slice in hypo_training_slices:\n",
    "\n",
    "    _030_values = slice.iloc[-24:-18]['GlucoseValue'].values\n",
    "    _3060_values = slice.iloc[-18:-12]['GlucoseValue'].values\n",
    "    _6090_values = slice.iloc[-12:-6]['GlucoseValue'].values\n",
    "    _90120_values = slice.iloc[-6:]['GlucoseValue'].values\n",
    "\n",
    "    _030_count = np.sum(_030_values < 70)\n",
    "    _3060_count = np.sum(_3060_values < 70)\n",
    "    _6090_count = np.sum(_6090_values < 70)\n",
    "    _90120_count = np.sum(_90120_values < 70)\n",
    "\n",
    "    min_points = 6\n",
    "\n",
    "    if _90120_count >= min_points:\n",
    "        _90120_slices.append(slice)\n",
    "    elif _6090_count >= min_points:\n",
    "        _6090_slices.append(slice)\n",
    "    elif _3060_count >= min_points:\n",
    "        _3060_slices.append(slice)\n",
    "    elif _030_count >= min_points:\n",
    "        _030_slices.append(slice)\n",
    "\n",
    "len(_030_slices), len(_3060_slices),len(_6090_slices), len(_90120_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110194"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiled_hypo_slices = _030_slices + _3060_slices + _6090_slices + _90120_slices\n",
    "\n",
    "len(profiled_hypo_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_training_dict = {idx: slice for idx, slice in enumerate(eu_training_slices)}\n",
    "hyper_training_dict = {idx: slice for idx, slice in enumerate(hyper_training_slices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = int(len(profiled_hypo_slices)/2)\n",
    "eu_training_dict = undersample_dict(eu_training_dict, target_size)\n",
    "eu_training_list = list(eu_training_dict.values())\n",
    "\n",
    "target_size = len(profiled_hypo_slices)\n",
    "\n",
    "hyper_training_dict = undersample_dict(hyper_training_dict, target_size)\n",
    "hyper_training_list = list(hyper_training_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55097, 110194)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eu_training_list), len(hyper_training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_slice_list = profiled_hypo_slices + eu_training_list + hyper_training_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Merge all the slices into a single DataFrame to calculate normalisation parameters\"\"\"\n",
    "training_df = pd.concat(training_slice_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 152.91051040286524, Std: 70.27050122812615\n",
      "\n",
      "GlucoseValue: Mean = 152.91051040286524, Std = 70.27050122812615\n",
      "5min_change: Mean = -0.14339721352574716, Std = 5.887838560788488\n",
      "30min_change: Mean = -0.9623103914971266, Std = 26.260806944012366\n",
      "1hr_change: Mean = -2.111818293675189, Std = 43.76900528191087\n",
      "1hr_mov_avg: Min = 39.0, Max = 401.0\n",
      "6hr_mov_avg: Min = 39.0, Max = 401.0\n",
      "1hr_mov_std: Min = 0.0, Max = 171.2240026716731\n",
      "6hr_mov_std: Min = 0.0, Max = 169.20324889498823\n",
      "1hr_largest_increase: Min = -18.0, Max = 339.0\n",
      "1hr_largest_decrease: Min = -355.0, Max = 19.0\n"
     ]
    }
   ],
   "source": [
    "z_score_list = [\"GlucoseValue\", \"5min_change\", \"30min_change\", \"1hr_change\"]\n",
    "\n",
    "min_max_list = [\n",
    "    \n",
    "    \"1hr_mov_avg\", \"6hr_mov_avg\",\n",
    "    \"1hr_mov_std\", \"6hr_mov_std\",\n",
    "    \"1hr_largest_increase\", \"1hr_largest_decrease\"\n",
    "]\n",
    "\n",
    "# Check the mean and standard deviation\n",
    "training_mean = training_df['GlucoseValue'].mean()\n",
    "training_std = training_df['GlucoseValue'].std()\n",
    "print(f\"Mean: {training_mean}, Std: {training_std}\\n\")\n",
    "\n",
    "mean_std_dict = {}\n",
    "min_max_dict = {}\n",
    "\n",
    "for col in z_score_list:\n",
    "    mean_std_dict[col] = (training_df[col].mean(), training_df[col].std())\n",
    "\n",
    "for col in z_score_list:\n",
    "    print(f\"{col}: Mean = {mean_std_dict[col][0]}, Std = {mean_std_dict[col][1]}\")\n",
    "\n",
    "for col in min_max_list:\n",
    "    min_max_dict[col] = (training_df[col].min(), training_df[col].max())\n",
    "\n",
    "for col in min_max_list:\n",
    "    print(f\"{col}: Min = {min_max_dict[col][0]}, Max = {min_max_dict[col][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_training_slices = []\n",
    "\n",
    "z_score_features = [\"GlucoseValue\", \"5min_change\", \"30min_change\", \"1hr_change\"]\n",
    "\n",
    "min_max_features = [\n",
    "    \n",
    "    \"1hr_mov_avg\", \"6hr_mov_avg\",\n",
    "    \"1hr_mov_std\", \"6hr_mov_std\",\n",
    "    \"1hr_largest_increase\", \"1hr_largest_decrease\"\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(training_df[min_max_features])\n",
    "# Normalize using z-score normalization for all columns in col_list\n",
    "\n",
    "for slice in training_slice_list:\n",
    "    slice = slice.copy()\n",
    "    for col in z_score_features:\n",
    "        slice.loc[:, col] = (slice[col] - mean_std_dict[col][0]) / mean_std_dict[col][1]\n",
    "\n",
    "    for col in min_max_features:\n",
    "        slice.loc[:, col] = (slice[col] - min_max_dict[col][0]) / (min_max_dict[col][1] - min_max_dict[col][0])\n",
    "\n",
    "    slice.drop(columns=['RollingTimeDiffFlag', 'PtID'], inplace=True)\n",
    "\n",
    "    normalised_training_slices.append(slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlucoseValue</th>\n",
       "      <th>5min_change</th>\n",
       "      <th>30min_change</th>\n",
       "      <th>1hr_change</th>\n",
       "      <th>1hr_mov_avg</th>\n",
       "      <th>1hr_mov_std</th>\n",
       "      <th>1hr_largest_increase</th>\n",
       "      <th>1hr_largest_decrease</th>\n",
       "      <th>6hr_mov_avg</th>\n",
       "      <th>6hr_mov_std</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>2.648188</td>\n",
       "      <td>-0.824853</td>\n",
       "      <td>0.036644</td>\n",
       "      <td>-0.134529</td>\n",
       "      <td>0.839779</td>\n",
       "      <td>0.028827</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.933155</td>\n",
       "      <td>0.769702</td>\n",
       "      <td>0.164906</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>2.605496</td>\n",
       "      <td>-0.485170</td>\n",
       "      <td>0.036644</td>\n",
       "      <td>-0.203070</td>\n",
       "      <td>0.837247</td>\n",
       "      <td>0.030035</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.933155</td>\n",
       "      <td>0.770699</td>\n",
       "      <td>0.165308</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>2.548573</td>\n",
       "      <td>-0.655012</td>\n",
       "      <td>-0.229913</td>\n",
       "      <td>-0.363001</td>\n",
       "      <td>0.833103</td>\n",
       "      <td>0.030648</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.933155</td>\n",
       "      <td>0.771159</td>\n",
       "      <td>0.165591</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>2.534342</td>\n",
       "      <td>-0.145487</td>\n",
       "      <td>-0.267992</td>\n",
       "      <td>-0.385848</td>\n",
       "      <td>0.828729</td>\n",
       "      <td>0.029255</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.933155</td>\n",
       "      <td>0.771351</td>\n",
       "      <td>0.165744</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>2.562804</td>\n",
       "      <td>0.364038</td>\n",
       "      <td>-0.267992</td>\n",
       "      <td>-0.317306</td>\n",
       "      <td>0.825046</td>\n",
       "      <td>0.024315</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.933155</td>\n",
       "      <td>0.771773</td>\n",
       "      <td>0.166043</td>\n",
       "      <td>17</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
       "656      2.648188    -0.824853      0.036644   -0.134529     0.839779   \n",
       "657      2.605496    -0.485170      0.036644   -0.203070     0.837247   \n",
       "658      2.548573    -0.655012     -0.229913   -0.363001     0.833103   \n",
       "659      2.534342    -0.145487     -0.267992   -0.385848     0.828729   \n",
       "660      2.562804     0.364038     -0.267992   -0.317306     0.825046   \n",
       "\n",
       "     1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
       "656     0.028827              0.058824              0.933155     0.769702   \n",
       "657     0.030035              0.058824              0.933155     0.770699   \n",
       "658     0.030648              0.058824              0.933155     0.771159   \n",
       "659     0.029255              0.058824              0.933155     0.771351   \n",
       "660     0.024315              0.058824              0.933155     0.771773   \n",
       "\n",
       "     6hr_mov_std  Hour  Minute  \n",
       "656     0.164906    17      21  \n",
       "657     0.165308    17      26  \n",
       "658     0.165591    17      31  \n",
       "659     0.165744    17      36  \n",
       "660     0.166043    17      41  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_training_slices[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/training/encoder_slices'\n",
    "decoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/training/decoder_slices'\n",
    "target_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/training/target_slices'\n",
    "\n",
    "os.makedirs(encoder_dir, exist_ok=True)\n",
    "os.makedirs(decoder_dir, exist_ok=True)\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Define columns to zero out in decoder input\n",
    "zero_out_columns = [\n",
    "    'GlucoseValue', '5min_change', '30min_change', '1hr_change', \n",
    "    '1hr_mov_avg', '1hr_mov_std', '1hr_largest_increase', \n",
    "    '1hr_largest_decrease', '6hr_mov_avg', '6hr_mov_std'\n",
    "]\n",
    "\n",
    "# Process slices efficiently\n",
    "for count, slice in enumerate(normalised_training_slices):\n",
    "\n",
    "    # Define Encoder, Decoder, and Target sequences (Avoid Copying)\n",
    "    encoder_input = slice.iloc[:encoder_input_size]\n",
    "    target = slice.iloc[encoder_input_size: ]['GlucoseValue']\n",
    "\n",
    "    # Modify Decoder Input In-Place (Vectorized)\n",
    "    decoder_input = slice.iloc[-decoder_input_size:].copy().reset_index(drop=True)\n",
    "    decoder_input.iloc[start_token_size:, decoder_input.columns.get_indexer(zero_out_columns)] = 0 \n",
    "    decoder_input = decoder_input.values  # Convert to NumPy array\n",
    "\n",
    "    # Define file paths\n",
    "    encoder_path = os.path.join(encoder_dir, f\"{count}.pt\")\n",
    "    decoder_path = os.path.join(decoder_dir, f\"{count}.pt\")\n",
    "    target_path = os.path.join(target_dir, f\"{count}.pt\")\n",
    "\n",
    "    # Save tensors without unnecessary copies\n",
    "    torch.save(torch.tensor(encoder_input.values, dtype=torch.float32), encoder_path)\n",
    "    torch.save(torch.tensor(decoder_input, dtype=torch.float32), decoder_path)\n",
    "    torch.save(torch.tensor(target.values, dtype=torch.float32), target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Encoder Shape: (72, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "67     -1.137184     0.873563      0.227042   -0.157376     0.081722   \n",
      "68     -1.051800     1.043404      0.798236    0.025402     0.081492   \n",
      "69     -1.009108     0.533880      0.988633    0.162485     0.082643   \n",
      "70     -0.966416     0.533880      0.988633    0.276721     0.084945   \n",
      "71     -0.952185     0.194196      0.874395    0.368110     0.088168   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "67     0.043023              0.064426              0.925134     0.205571   \n",
      "68     0.042225              0.067227              0.925134     0.204612   \n",
      "69     0.046017              0.067227              0.925134     0.203729   \n",
      "70     0.052717              0.067227              0.925134     0.203000   \n",
      "71     0.059427              0.067227              0.925134     0.202386   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "67     0.176790   3.0    14.0  \n",
      "68     0.178296   3.0    19.0  \n",
      "69     0.179523   3.0    24.0  \n",
      "70     0.180464   3.0    29.0  \n",
      "71     0.181264   3.0    34.0  \n",
      "\n",
      " Decoder Shape: (36, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "6      -1.208338     0.703721     -0.039515   -0.340154     0.083794   \n",
      "7      -1.137184     0.873563      0.227042   -0.157376     0.081722   \n",
      "8      -1.051800     1.043404      0.798236    0.025402     0.081492   \n",
      "9      -1.009108     0.533880      0.988633    0.162485     0.082643   \n",
      "10     -0.966416     0.533880      0.988633    0.276721     0.084945   \n",
      "11     -0.952185     0.194196      0.874395    0.368110     0.088168   \n",
      "12      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "13      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "14      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "15      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "16      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "17      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "18      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "19      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "20      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "21      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "22      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "23      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "24      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "25      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "26      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "27      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "28      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "29      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "30      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "31      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "32      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "33      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "34      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "35      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "6      0.048246              0.061625              0.925134     0.206760   \n",
      "7      0.043023              0.064426              0.925134     0.205571   \n",
      "8      0.042225              0.067227              0.925134     0.204612   \n",
      "9      0.046017              0.067227              0.925134     0.203729   \n",
      "10     0.052717              0.067227              0.925134     0.203000   \n",
      "11     0.059427              0.067227              0.925134     0.202386   \n",
      "12     0.000000              0.000000              0.000000     0.000000   \n",
      "13     0.000000              0.000000              0.000000     0.000000   \n",
      "14     0.000000              0.000000              0.000000     0.000000   \n",
      "15     0.000000              0.000000              0.000000     0.000000   \n",
      "16     0.000000              0.000000              0.000000     0.000000   \n",
      "17     0.000000              0.000000              0.000000     0.000000   \n",
      "18     0.000000              0.000000              0.000000     0.000000   \n",
      "19     0.000000              0.000000              0.000000     0.000000   \n",
      "20     0.000000              0.000000              0.000000     0.000000   \n",
      "21     0.000000              0.000000              0.000000     0.000000   \n",
      "22     0.000000              0.000000              0.000000     0.000000   \n",
      "23     0.000000              0.000000              0.000000     0.000000   \n",
      "24     0.000000              0.000000              0.000000     0.000000   \n",
      "25     0.000000              0.000000              0.000000     0.000000   \n",
      "26     0.000000              0.000000              0.000000     0.000000   \n",
      "27     0.000000              0.000000              0.000000     0.000000   \n",
      "28     0.000000              0.000000              0.000000     0.000000   \n",
      "29     0.000000              0.000000              0.000000     0.000000   \n",
      "30     0.000000              0.000000              0.000000     0.000000   \n",
      "31     0.000000              0.000000              0.000000     0.000000   \n",
      "32     0.000000              0.000000              0.000000     0.000000   \n",
      "33     0.000000              0.000000              0.000000     0.000000   \n",
      "34     0.000000              0.000000              0.000000     0.000000   \n",
      "35     0.000000              0.000000              0.000000     0.000000   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "6      0.174608   3.0     9.0  \n",
      "7      0.176790   3.0    14.0  \n",
      "8      0.178296   3.0    19.0  \n",
      "9      0.179523   3.0    24.0  \n",
      "10     0.180464   3.0    29.0  \n",
      "11     0.181264   3.0    34.0  \n",
      "12     0.000000   3.0    39.0  \n",
      "13     0.000000   3.0    44.0  \n",
      "14     0.000000   3.0    49.0  \n",
      "15     0.000000   3.0    54.0  \n",
      "16     0.000000   3.0    59.0  \n",
      "17     0.000000   4.0     4.0  \n",
      "18     0.000000   4.0     9.0  \n",
      "19     0.000000   4.0    14.0  \n",
      "20     0.000000   4.0    19.0  \n",
      "21     0.000000   4.0    24.0  \n",
      "22     0.000000   4.0    29.0  \n",
      "23     0.000000   4.0    34.0  \n",
      "24     0.000000   4.0    39.0  \n",
      "25     0.000000   4.0    44.0  \n",
      "26     0.000000   4.0    49.0  \n",
      "27     0.000000   4.0    54.0  \n",
      "28     0.000000   4.0    59.0  \n",
      "29     0.000000   5.0     4.0  \n",
      "30     0.000000   5.0     9.0  \n",
      "31     0.000000   5.0    14.0  \n",
      "32     0.000000   5.0    19.0  \n",
      "33     0.000000   5.0    24.0  \n",
      "34     0.000000   5.0    29.0  \n",
      "35     0.000000   5.0    34.0  \n",
      "\n",
      " Target Shape: (24, 1)\n",
      "    GlucoseValue\n",
      "19     -1.379107\n",
      "20     -1.364876\n",
      "21     -1.364876\n",
      "22     -1.393337\n",
      "23     -1.393337\n"
     ]
    }
   ],
   "source": [
    "encoder_file = get_first_file(encoder_dir)\n",
    "decoder_file = get_first_file(decoder_dir)\n",
    "target_file = get_first_file(target_dir)\n",
    "\n",
    "encoder_tensor = torch.load(encoder_file)\n",
    "decoder_tensor = torch.load(decoder_file)\n",
    "target_tensor = torch.load(target_file)\n",
    "\n",
    "\n",
    "encoder_df = pd.DataFrame(encoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "decoder_df = pd.DataFrame(decoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "target_df = pd.DataFrame(target_tensor.numpy(), columns=[\"GlucoseValue\"])\n",
    "\n",
    "print(f\"\\n Encoder Shape: {encoder_df.shape}\")\n",
    "print(encoder_df.tail())\n",
    "print(f\"\\n Decoder Shape: {decoder_df.shape}\")\n",
    "print(decoder_df.tail(30))\n",
    "print(f\"\\n Target Shape: {target_df.shape}\")\n",
    "print(target_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.    ReplaceBG Validation Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ptid, df in replace_cgm_validation_data.items():\n",
    "    df = df.copy()\n",
    "    df['real_value_flag'] = 1\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "\n",
    "    # Identify rows where TimeDiff is around 600 seconds (10 min)\n",
    "    mask = (df['TimeDiff'] > 595) & (df['TimeDiff'] < 605)\n",
    "    insert_rows = df[mask].copy()\n",
    "\n",
    "    if not insert_rows.empty:\n",
    "        # Modify new rows: set `real_value_flag = 0`, shift `DateTime`, and set `GlucoseValue = NaN`\n",
    "        insert_rows['real_value_flag'] = 0\n",
    "        insert_rows['DateTime'] -= pd.to_timedelta(5, unit='m')\n",
    "        insert_rows['GlucoseValue'] = np.nan\n",
    "\n",
    "        # Append new rows to the dataframe and sort\n",
    "    df = pd.concat([df, insert_rows]).sort_values(by='DateTime').reset_index(drop=True)\n",
    "\n",
    "    # Linearly interpolate the glucose value\n",
    "    df['GlucoseValue'] = df['GlucoseValue'].interpolate(method='linear')\n",
    "            \n",
    "    df['5min_change'] = df['GlucoseValue'].diff(1)\n",
    "    df['30min_change'] = df['GlucoseValue'].diff(6)\n",
    "    df['1hr_change'] = df['GlucoseValue'].diff(12)\n",
    "\n",
    "    df['1hr_mov_avg'] = df['GlucoseValue'].rolling(window=12).mean()\n",
    "    df['1hr_mov_std'] = df['GlucoseValue'].rolling(window=12).std()\n",
    "\n",
    "    df['1hr_largest_increase'] = df['5min_change'].rolling(window=12).max()\n",
    "    df['1hr_largest_decrease'] = df['5min_change'].rolling(window=12).min()\n",
    "\n",
    "    df['6hr_mov_avg'] = df['GlucoseValue'].rolling(window=72).mean()\n",
    "    df['6hr_mov_std'] = df['GlucoseValue'].rolling(window=72).std()\n",
    "\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "    df['TimeDiffFlag'] = df['TimeDiff'].apply(lambda x: 0 if x < 295 or x > 305 else 1)\n",
    "    df['RollingTimeDiffFlag'] = df['TimeDiffFlag'].rolling(window=96).sum()\n",
    "\n",
    "    # Drop first 72 rows due to NaN values\n",
    "    df = df.iloc[72:].reset_index(drop=True)\n",
    "\n",
    "    # drop columns\n",
    "    df = df.drop(columns=['DateTime', 'TimeDiff', 'TimeDiffFlag', 'real_value_flag'])\n",
    "\n",
    "    replace_cgm_validation_data[ptid] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create slices of total input length\n",
    "\n",
    "replace_validation_slices = []\n",
    "\n",
    "for ptid, df in replace_cgm_validation_data.items():\n",
    "    if 'RollingTimeDiffFlag' not in df.columns:\n",
    "        continue  # Skip this dataframe if the column does not exist\n",
    "    rolling_flag_array = df[\"RollingTimeDiffFlag\"].to_numpy()  # Convert to NumPy array for fast indexing\n",
    "    num_rows = len(df)\n",
    "    starting_index = 0\n",
    "\n",
    "    while starting_index + slice_size <= num_rows:\n",
    "        if rolling_flag_array[starting_index + slice_size - 1] == slice_size:  # Use precomputed array\n",
    "            replace_validation_slices.append(df.iloc[starting_index:starting_index + slice_size])\n",
    "            starting_index += overlap  # Move by overlap\n",
    "        else:\n",
    "            starting_index += 1  # Ensure progress to avoid infinite loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252182"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replace_validation_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dict = {idx: slice for idx, slice in enumerate(replace_validation_slices)}\n",
    "\n",
    "target_size = int(len(validation_dict)/2)\n",
    "\n",
    "undersampled_validation_dict = undersample_dict(validation_dict, target_size)\n",
    "\n",
    "validation_list = list(undersampled_validation_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_validation_slices = []\n",
    "\n",
    "z_score_features = [\"GlucoseValue\", \"5min_change\", \"30min_change\", \"1hr_change\"]\n",
    "\n",
    "min_max_features = [\n",
    "    \n",
    "    \"1hr_mov_avg\", \"6hr_mov_avg\",\n",
    "    \"1hr_mov_std\", \"6hr_mov_std\",\n",
    "    \"1hr_largest_increase\", \"1hr_largest_decrease\"\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(training_df[min_max_features])\n",
    "# Normalize using z-score normalization for all columns in col_list\n",
    "\n",
    "for slice in validation_list:\n",
    "    slice = slice.copy()\n",
    "    for col in z_score_features:\n",
    "        slice.loc[:, col] = (slice[col] - mean_std_dict[col][0]) / mean_std_dict[col][1]\n",
    "\n",
    "    for col in min_max_features:\n",
    "        slice.loc[:, col] = (slice[col] - min_max_dict[col][0]) / (min_max_dict[col][1] - min_max_dict[col][0])\n",
    "\n",
    "    slice.drop(columns=['RollingTimeDiffFlag', 'PtID'], inplace=True)\n",
    "\n",
    "    normalised_validation_slices.append(slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126091"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalised_validation_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlucoseValue</th>\n",
       "      <th>5min_change</th>\n",
       "      <th>30min_change</th>\n",
       "      <th>1hr_change</th>\n",
       "      <th>1hr_mov_avg</th>\n",
       "      <th>1hr_mov_std</th>\n",
       "      <th>1hr_largest_increase</th>\n",
       "      <th>1hr_largest_decrease</th>\n",
       "      <th>6hr_mov_avg</th>\n",
       "      <th>6hr_mov_std</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>0.670117</td>\n",
       "      <td>0.364038</td>\n",
       "      <td>0.455520</td>\n",
       "      <td>0.665124</td>\n",
       "      <td>0.416206</td>\n",
       "      <td>0.049951</td>\n",
       "      <td>0.061625</td>\n",
       "      <td>0.949198</td>\n",
       "      <td>0.328614</td>\n",
       "      <td>0.105375</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>0.670117</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>0.303201</td>\n",
       "      <td>0.619430</td>\n",
       "      <td>0.421961</td>\n",
       "      <td>0.044696</td>\n",
       "      <td>0.061625</td>\n",
       "      <td>0.949198</td>\n",
       "      <td>0.330878</td>\n",
       "      <td>0.108665</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>0.655887</td>\n",
       "      <td>-0.145487</td>\n",
       "      <td>0.150883</td>\n",
       "      <td>0.528041</td>\n",
       "      <td>0.426796</td>\n",
       "      <td>0.038216</td>\n",
       "      <td>0.061625</td>\n",
       "      <td>0.946524</td>\n",
       "      <td>0.333180</td>\n",
       "      <td>0.111297</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>0.627425</td>\n",
       "      <td>-0.315328</td>\n",
       "      <td>0.036644</td>\n",
       "      <td>0.390957</td>\n",
       "      <td>0.430249</td>\n",
       "      <td>0.032098</td>\n",
       "      <td>0.061625</td>\n",
       "      <td>0.943850</td>\n",
       "      <td>0.335482</td>\n",
       "      <td>0.113131</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>0.670117</td>\n",
       "      <td>0.533880</td>\n",
       "      <td>0.112803</td>\n",
       "      <td>0.390957</td>\n",
       "      <td>0.433702</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>0.061625</td>\n",
       "      <td>0.943850</td>\n",
       "      <td>0.337937</td>\n",
       "      <td>0.115093</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
       "3080      0.670117     0.364038      0.455520    0.665124     0.416206   \n",
       "3081      0.670117     0.024355      0.303201    0.619430     0.421961   \n",
       "3082      0.655887    -0.145487      0.150883    0.528041     0.426796   \n",
       "3083      0.627425    -0.315328      0.036644    0.390957     0.430249   \n",
       "3084      0.670117     0.533880      0.112803    0.390957     0.433702   \n",
       "\n",
       "      1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
       "3080     0.049951              0.061625              0.949198     0.328614   \n",
       "3081     0.044696              0.061625              0.949198     0.330878   \n",
       "3082     0.038216              0.061625              0.946524     0.333180   \n",
       "3083     0.032098              0.061625              0.943850     0.335482   \n",
       "3084     0.027619              0.061625              0.943850     0.337937   \n",
       "\n",
       "      6hr_mov_std  Hour  Minute  \n",
       "3080     0.105375     5      27  \n",
       "3081     0.108665     5      32  \n",
       "3082     0.111297     5      37  \n",
       "3083     0.113131     5      42  \n",
       "3084     0.115093     5      47  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first  5 rows of the first slice    \n",
    "normalised_validation_slices[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "encoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/validation/encoder_slices'\n",
    "decoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/validation/decoder_slices'\n",
    "target_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/validation/target_slices'\n",
    "\n",
    "\n",
    "os.makedirs(encoder_dir, exist_ok=True)\n",
    "os.makedirs(decoder_dir, exist_ok=True)\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "for count, slice in enumerate(normalised_validation_slices):\n",
    "    # Define Encoder, Decoder, and Target sequences (Avoid Copying)\n",
    "    encoder_input = slice.iloc[:encoder_input_size]\n",
    "    target = slice.iloc[encoder_input_size: ]['GlucoseValue']\n",
    "\n",
    "\n",
    "    # Modify Decoder Input In-Place (Vectorized)\n",
    "    decoder_input = slice.iloc[-decoder_input_size:].copy().reset_index(drop=True)  # Copy last 36 rows\n",
    "    decoder_input.iloc[start_token_size:, decoder_input.columns.get_indexer(zero_out_columns)] = 0 \n",
    "    decoder_input = decoder_input.values  # Convert to NumPy array\n",
    "\n",
    "    # Define file paths\n",
    "    encoder_path = os.path.join(encoder_dir, f\"{count}.pt\")\n",
    "    decoder_path = os.path.join(decoder_dir, f\"{count}.pt\")\n",
    "    target_path = os.path.join(target_dir, f\"{count}.pt\")\n",
    "\n",
    "    # Save tensors without unnecessary copies\n",
    "    # Save tensors without unnecessary copies\n",
    "    torch.save(torch.tensor(encoder_input.values, dtype=torch.float32), encoder_path)\n",
    "    torch.save(torch.tensor(decoder_input, dtype=torch.float32), decoder_path)\n",
    "    torch.save(torch.tensor(target.values, dtype=torch.float32), target_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Encoder Shape: (72, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "67     -0.952185    -0.145487      0.036644    0.128214     0.126842   \n",
      "68     -0.966416    -0.145487     -0.039515    0.139638     0.127762   \n",
      "69     -0.980646    -0.145487     -0.115674    0.116791     0.128453   \n",
      "70     -1.009108    -0.315328     -0.191833    0.071096     0.128683   \n",
      "71     -1.066031    -0.655012     -0.344151   -0.043140     0.127762   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "67     0.017156              0.056022              0.945187     0.340700   \n",
      "68     0.015577              0.056022              0.946524     0.335981   \n",
      "69     0.013753              0.056022              0.946524     0.331031   \n",
      "70     0.012810              0.056022              0.943850     0.325852   \n",
      "71     0.017276              0.056022              0.938503     0.320404   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "67     0.333422  14.0    10.0  \n",
      "68     0.336130  14.0    15.0  \n",
      "69     0.338243  14.0    20.0  \n",
      "70     0.339888  14.0    25.0  \n",
      "71     0.341318  14.0    30.0  \n",
      "\n",
      " Decoder Shape: (36, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "6      -0.937954    -0.145487      0.150883    0.116791     0.126036   \n",
      "7      -0.952185    -0.145487      0.036644    0.128214     0.126842   \n",
      "8      -0.966416    -0.145487     -0.039515    0.139638     0.127762   \n",
      "9      -0.980646    -0.145487     -0.115674    0.116791     0.128453   \n",
      "10     -1.009108    -0.315328     -0.191833    0.071096     0.128683   \n",
      "11     -1.066031    -0.655012     -0.344151   -0.043140     0.127762   \n",
      "12      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "13      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "14      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "15      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "16      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "17      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "18      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "19      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "20      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "21      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "22      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "23      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "24      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "25      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "26      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "27      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "28      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "29      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "30      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "31      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "32      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "33      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "34      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "35      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "6      0.017482              0.056022              0.945187     0.345227   \n",
      "7      0.017156              0.056022              0.945187     0.340700   \n",
      "8      0.015577              0.056022              0.946524     0.335981   \n",
      "9      0.013753              0.056022              0.946524     0.331031   \n",
      "10     0.012810              0.056022              0.943850     0.325852   \n",
      "11     0.017276              0.056022              0.938503     0.320404   \n",
      "12     0.000000              0.000000              0.000000     0.000000   \n",
      "13     0.000000              0.000000              0.000000     0.000000   \n",
      "14     0.000000              0.000000              0.000000     0.000000   \n",
      "15     0.000000              0.000000              0.000000     0.000000   \n",
      "16     0.000000              0.000000              0.000000     0.000000   \n",
      "17     0.000000              0.000000              0.000000     0.000000   \n",
      "18     0.000000              0.000000              0.000000     0.000000   \n",
      "19     0.000000              0.000000              0.000000     0.000000   \n",
      "20     0.000000              0.000000              0.000000     0.000000   \n",
      "21     0.000000              0.000000              0.000000     0.000000   \n",
      "22     0.000000              0.000000              0.000000     0.000000   \n",
      "23     0.000000              0.000000              0.000000     0.000000   \n",
      "24     0.000000              0.000000              0.000000     0.000000   \n",
      "25     0.000000              0.000000              0.000000     0.000000   \n",
      "26     0.000000              0.000000              0.000000     0.000000   \n",
      "27     0.000000              0.000000              0.000000     0.000000   \n",
      "28     0.000000              0.000000              0.000000     0.000000   \n",
      "29     0.000000              0.000000              0.000000     0.000000   \n",
      "30     0.000000              0.000000              0.000000     0.000000   \n",
      "31     0.000000              0.000000              0.000000     0.000000   \n",
      "32     0.000000              0.000000              0.000000     0.000000   \n",
      "33     0.000000              0.000000              0.000000     0.000000   \n",
      "34     0.000000              0.000000              0.000000     0.000000   \n",
      "35     0.000000              0.000000              0.000000     0.000000   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "6      0.330247  14.0     5.0  \n",
      "7      0.333422  14.0    10.0  \n",
      "8      0.336130  14.0    15.0  \n",
      "9      0.338243  14.0    20.0  \n",
      "10     0.339888  14.0    25.0  \n",
      "11     0.341318  14.0    30.0  \n",
      "12     0.000000  14.0    35.0  \n",
      "13     0.000000  14.0    40.0  \n",
      "14     0.000000  14.0    45.0  \n",
      "15     0.000000  14.0    50.0  \n",
      "16     0.000000  14.0    55.0  \n",
      "17     0.000000  15.0     0.0  \n",
      "18     0.000000  15.0     5.0  \n",
      "19     0.000000  15.0    10.0  \n",
      "20     0.000000  15.0    15.0  \n",
      "21     0.000000  15.0    20.0  \n",
      "22     0.000000  15.0    25.0  \n",
      "23     0.000000  15.0    30.0  \n",
      "24     0.000000  15.0    35.0  \n",
      "25     0.000000  15.0    40.0  \n",
      "26     0.000000  15.0    45.0  \n",
      "27     0.000000  15.0    50.0  \n",
      "28     0.000000  15.0    55.0  \n",
      "29     0.000000  16.0     0.0  \n",
      "30     0.000000  16.0     5.0  \n",
      "31     0.000000  16.0    10.0  \n",
      "32     0.000000  16.0    15.0  \n",
      "33     0.000000  16.0    20.0  \n",
      "34     0.000000  16.0    25.0  \n",
      "35     0.000000  16.0    30.0  \n",
      "\n",
      " Target Shape: (24, 1)\n",
      "    GlucoseValue\n",
      "19      0.285888\n",
      "20      0.271657\n",
      "21      0.243196\n",
      "22      0.214734\n",
      "23      0.186273\n"
     ]
    }
   ],
   "source": [
    "encoder_file = get_first_file(encoder_dir)\n",
    "decoder_file = get_first_file(decoder_dir)\n",
    "target_file = get_first_file(target_dir)\n",
    "\n",
    "encoder_tensor = torch.load(encoder_file)\n",
    "decoder_tensor = torch.load(decoder_file)\n",
    "target_tensor = torch.load(target_file)\n",
    "\n",
    "\n",
    "encoder_df = pd.DataFrame(encoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "decoder_df = pd.DataFrame(decoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "target_df = pd.DataFrame(target_tensor.numpy(), columns=[\"GlucoseValue\"])\n",
    "\n",
    "print(f\"\\n Encoder Shape: {encoder_df.shape}\")\n",
    "print(encoder_df.tail())\n",
    "print(f\"\\n Decoder Shape: {decoder_df.shape}\")\n",
    "print(decoder_df.tail(30))\n",
    "print(f\"\\n Target Shape: {target_df.shape}\")\n",
    "print(target_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.    ReplaceBG Test Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ptid, df in replace_cgm_test_data.items():\n",
    "    df = df.copy()\n",
    "    df['real_value_flag'] = 1\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "\n",
    "    # Identify rows where TimeDiff is around 600 seconds (10 min)\n",
    "    mask = (df['TimeDiff'] > 595) & (df['TimeDiff'] < 605)\n",
    "    insert_rows = df[mask].copy()\n",
    "\n",
    "    if not insert_rows.empty:\n",
    "        # Modify new rows: set `real_value_flag = 0`, shift `DateTime`, and set `GlucoseValue = NaN`\n",
    "        insert_rows['real_value_flag'] = 0\n",
    "        insert_rows['DateTime'] -= pd.to_timedelta(5, unit='m')\n",
    "        insert_rows['GlucoseValue'] = np.nan\n",
    "\n",
    "        # Append new rows to the dataframe and sort\n",
    "    df = pd.concat([df, insert_rows]).sort_values(by='DateTime').reset_index(drop=True)\n",
    "\n",
    "    # Linearly interpolate the glucose value\n",
    "    df['GlucoseValue'] = df['GlucoseValue'].interpolate(method='linear')\n",
    "            \n",
    "    df['5min_change'] = df['GlucoseValue'].diff(1)\n",
    "    df['30min_change'] = df['GlucoseValue'].diff(6)\n",
    "    df['1hr_change'] = df['GlucoseValue'].diff(12)\n",
    "\n",
    "    df['1hr_mov_avg'] = df['GlucoseValue'].rolling(window=12).mean()\n",
    "    df['1hr_mov_std'] = df['GlucoseValue'].rolling(window=12).std()\n",
    "\n",
    "    df['1hr_largest_increase'] = df['5min_change'].rolling(window=12).max()\n",
    "    df['1hr_largest_decrease'] = df['5min_change'].rolling(window=12).min()\n",
    "\n",
    "    df['6hr_mov_avg'] = df['GlucoseValue'].rolling(window=72).mean()\n",
    "    df['6hr_mov_std'] = df['GlucoseValue'].rolling(window=72).std()\n",
    "\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    df['TimeDiff'] = df['DateTime'].diff().dt.total_seconds()\n",
    "    df['TimeDiffFlag'] = df['TimeDiff'].apply(lambda x: 0 if x < 295 or x > 305 else 1)\n",
    "    df['RollingTimeDiffFlag'] = df['TimeDiffFlag'].rolling(window=96).sum()\n",
    "\n",
    "    # Drop first 72 rows due to NaN values\n",
    "    df = df.iloc[72:].reset_index(drop=True)\n",
    "\n",
    "    # drop columns\n",
    "    df = df.drop(columns=['DateTime', 'TimeDiff', 'TimeDiffFlag', 'real_value_flag'])\n",
    "\n",
    "    replace_cgm_test_data[ptid] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_test_slices = []\n",
    "\n",
    "for ptid, df in replace_cgm_test_data.items():\n",
    "    if 'RollingTimeDiffFlag' not in df.columns:\n",
    "        continue  # Skip this dataframe if the column does not exist\n",
    "    rolling_flag_array = df[\"RollingTimeDiffFlag\"].to_numpy()  # Convert to NumPy array for fast indexing\n",
    "    num_rows = len(df)\n",
    "    starting_index = 0\n",
    "\n",
    "    while starting_index + slice_size <= num_rows:\n",
    "        if rolling_flag_array[starting_index + slice_size - 1] == slice_size:  # Use precomputed array\n",
    "            replace_test_slices.append(df.iloc[starting_index:starting_index + slice_size])\n",
    "            starting_index += overlap  # Move by overlap\n",
    "        else:\n",
    "            starting_index += 1  # Ensure progress to avoid infinite loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280632"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replace_test_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {idx: slice for idx, slice in enumerate(replace_test_slices)}\n",
    "\n",
    "target_size = int(len(test_dict)/2)\n",
    "\n",
    "undersampled_test_dict = undersample_dict(test_dict, target_size)\n",
    "\n",
    "test_list = list(undersampled_test_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_test_slices = []\n",
    "\n",
    "z_score_features = [\"GlucoseValue\", \"5min_change\", \"30min_change\", \"1hr_change\"]\n",
    "\n",
    "min_max_features = [\n",
    "    \n",
    "    \"1hr_mov_avg\", \"6hr_mov_avg\",\n",
    "    \"1hr_mov_std\", \"6hr_mov_std\",\n",
    "    \"1hr_largest_increase\", \"1hr_largest_decrease\"\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(training_df[min_max_features])\n",
    "# Normalize using z-score normalization for all columns in col_list\n",
    "\n",
    "for slice in test_list:\n",
    "    slice = slice.copy()\n",
    "    for col in z_score_features:\n",
    "        slice.loc[:, col] = (slice[col] - mean_std_dict[col][0]) / mean_std_dict[col][1]\n",
    "\n",
    "    for col in min_max_features:\n",
    "        slice.loc[:, col] = (slice[col] - min_max_dict[col][0]) / (min_max_dict[col][1] - min_max_dict[col][0])\n",
    "\n",
    "    slice.drop(columns=['RollingTimeDiffFlag', 'PtID'], inplace=True)\n",
    "\n",
    "    normalised_test_slices.append(slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlucoseValue</th>\n",
       "      <th>5min_change</th>\n",
       "      <th>30min_change</th>\n",
       "      <th>1hr_change</th>\n",
       "      <th>1hr_mov_avg</th>\n",
       "      <th>1hr_mov_std</th>\n",
       "      <th>1hr_largest_increase</th>\n",
       "      <th>1hr_largest_decrease</th>\n",
       "      <th>6hr_mov_avg</th>\n",
       "      <th>6hr_mov_std</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>0.641656</td>\n",
       "      <td>0.703721</td>\n",
       "      <td>-0.382231</td>\n",
       "      <td>0.299569</td>\n",
       "      <td>0.454420</td>\n",
       "      <td>0.043241</td>\n",
       "      <td>0.081232</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.494475</td>\n",
       "      <td>0.145535</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>0.698579</td>\n",
       "      <td>0.703721</td>\n",
       "      <td>-0.077594</td>\n",
       "      <td>0.139638</td>\n",
       "      <td>0.455341</td>\n",
       "      <td>0.042176</td>\n",
       "      <td>0.070028</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.493823</td>\n",
       "      <td>0.145959</td>\n",
       "      <td>19</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>0.812425</td>\n",
       "      <td>1.383088</td>\n",
       "      <td>0.303201</td>\n",
       "      <td>0.162485</td>\n",
       "      <td>0.456492</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>0.072829</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.493362</td>\n",
       "      <td>0.146027</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>0.997424</td>\n",
       "      <td>2.232296</td>\n",
       "      <td>0.988633</td>\n",
       "      <td>0.299569</td>\n",
       "      <td>0.459024</td>\n",
       "      <td>0.052523</td>\n",
       "      <td>0.086835</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.493094</td>\n",
       "      <td>0.145816</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>1.182423</td>\n",
       "      <td>2.232296</td>\n",
       "      <td>1.674065</td>\n",
       "      <td>0.528041</td>\n",
       "      <td>0.463858</td>\n",
       "      <td>0.072752</td>\n",
       "      <td>0.086835</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.493171</td>\n",
       "      <td>0.145934</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
       "1164      0.641656     0.703721     -0.382231    0.299569     0.454420   \n",
       "1165      0.698579     0.703721     -0.077594    0.139638     0.455341   \n",
       "1166      0.812425     1.383088      0.303201    0.162485     0.456492   \n",
       "1167      0.997424     2.232296      0.988633    0.299569     0.459024   \n",
       "1168      1.182423     2.232296      1.674065    0.528041     0.463858   \n",
       "\n",
       "      1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
       "1164     0.043241              0.081232              0.935829     0.494475   \n",
       "1165     0.042176              0.070028              0.935829     0.493823   \n",
       "1166     0.043429              0.072829              0.935829     0.493362   \n",
       "1167     0.052523              0.086835              0.935829     0.493094   \n",
       "1168     0.072752              0.086835              0.935829     0.493171   \n",
       "\n",
       "      6hr_mov_std  Hour  Minute  \n",
       "1164     0.145535    19      50  \n",
       "1165     0.145959    19      55  \n",
       "1166     0.146027    20       0  \n",
       "1167     0.145816    20       5  \n",
       "1168     0.145934    20      10  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_test_slices[0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert replce_test_slices to dictionary\n",
    "replace_test_dict = {idx: slice for idx, slice in enumerate(normalised_test_slices)}\n",
    "\n",
    "target_size = len(replace_test_dict)  # Match validation count\n",
    "\n",
    "replace_test_dict = undersample_dict(replace_test_dict, target_size)\n",
    "\n",
    "test_slice_list = list(replace_test_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140316"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_slice_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/testing/encoder_slices'\n",
    "decoder_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/testing/decoder_slices'\n",
    "target_dir = '../processed_data/replace_bg/baseline_with_feature_enhancement_211_undersample/testing/target_slices'\n",
    "\n",
    "os.makedirs(encoder_dir, exist_ok=True)\n",
    "os.makedirs(decoder_dir, exist_ok=True)\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for count, slice in enumerate(test_slice_list):\n",
    "    # Define Encoder, Decoder, and Target sequences (Avoid Copying)\n",
    "    encoder_input = slice.iloc[:encoder_input_size]\n",
    "    target = slice.iloc[encoder_input_size: ]['GlucoseValue']\n",
    "\n",
    "    # Modify Decoder Input In-Place (Vectorized)\n",
    "    decoder_input = slice.iloc[-decoder_input_size:].copy().reset_index(drop=True)  # Copy last 36 rows\n",
    "    decoder_input.iloc[start_token_size:, decoder_input.columns.get_indexer(zero_out_columns)] = 0 \n",
    "    decoder_input = decoder_input.values  # Convert to NumPy array\n",
    "\n",
    "    # Define file paths\n",
    "    encoder_path = os.path.join(encoder_dir, f\"{count}.pt\")\n",
    "    decoder_path = os.path.join(decoder_dir, f\"{count}.pt\")\n",
    "    target_path = os.path.join(target_dir, f\"{count}.pt\")\n",
    "\n",
    "    # Save tensors without unnecessary copies\n",
    "    torch.save(torch.tensor(encoder_input.values, dtype=torch.float32), encoder_path)\n",
    "    torch.save(torch.tensor(decoder_input, dtype=torch.float32), decoder_path)\n",
    "    torch.save(torch.tensor(target.values, dtype=torch.float32), target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Encoder Shape: (72, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "67     -0.752955    -0.485170     -0.610708   -0.340154     0.207413   \n",
      "68     -0.724493     0.364038     -0.382231   -0.454390     0.202348   \n",
      "69     -0.639109     1.043404     -0.001435   -0.408695     0.197744   \n",
      "70     -0.567955     0.873563      0.341281   -0.225917     0.194982   \n",
      "71     -0.525263     0.533880      0.531679   -0.088834     0.193600   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "67     0.057626              0.070028              0.938503     0.287063   \n",
      "68     0.057823              0.061625              0.938503     0.281039   \n",
      "69     0.050268              0.067227              0.938503     0.275284   \n",
      "70     0.043166              0.067227              0.938503     0.270066   \n",
      "71     0.038777              0.067227              0.938503     0.265308   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "67     0.269853  17.0    45.0  \n",
      "68     0.258547  17.0    50.0  \n",
      "69     0.245877  17.0    55.0  \n",
      "70     0.233800  18.0     0.0  \n",
      "71     0.222545  18.0     5.0  \n",
      "\n",
      " Decoder Shape: (36, 12)\n",
      "    GlucoseValue  5min_change  30min_change  1hr_change  1hr_mov_avg  \\\n",
      "6      -0.710263     0.024355     -0.610708   -0.111681     0.211326   \n",
      "7      -0.752955    -0.485170     -0.610708   -0.340154     0.207413   \n",
      "8      -0.724493     0.364038     -0.382231   -0.454390     0.202348   \n",
      "9      -0.639109     1.043404     -0.001435   -0.408695     0.197744   \n",
      "10     -0.567955     0.873563      0.341281   -0.225917     0.194982   \n",
      "11     -0.525263     0.533880      0.531679   -0.088834     0.193600   \n",
      "12      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "13      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "14      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "15      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "16      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "17      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "18      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "19      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "20      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "21      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "22      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "23      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "24      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "25      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "26      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "27      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "28      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "29      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "30      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "31      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "32      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "33      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "34      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "35      0.000000     0.000000      0.000000    0.000000     0.000000   \n",
      "\n",
      "    1hr_mov_std  1hr_largest_increase  1hr_largest_decrease  6hr_mov_avg  \\\n",
      "6      0.051550              0.070028              0.938503     0.293278   \n",
      "7      0.057626              0.070028              0.938503     0.287063   \n",
      "8      0.057823              0.061625              0.938503     0.281039   \n",
      "9      0.050268              0.067227              0.938503     0.275284   \n",
      "10     0.043166              0.067227              0.938503     0.270066   \n",
      "11     0.038777              0.067227              0.938503     0.265308   \n",
      "12     0.000000              0.000000              0.000000     0.000000   \n",
      "13     0.000000              0.000000              0.000000     0.000000   \n",
      "14     0.000000              0.000000              0.000000     0.000000   \n",
      "15     0.000000              0.000000              0.000000     0.000000   \n",
      "16     0.000000              0.000000              0.000000     0.000000   \n",
      "17     0.000000              0.000000              0.000000     0.000000   \n",
      "18     0.000000              0.000000              0.000000     0.000000   \n",
      "19     0.000000              0.000000              0.000000     0.000000   \n",
      "20     0.000000              0.000000              0.000000     0.000000   \n",
      "21     0.000000              0.000000              0.000000     0.000000   \n",
      "22     0.000000              0.000000              0.000000     0.000000   \n",
      "23     0.000000              0.000000              0.000000     0.000000   \n",
      "24     0.000000              0.000000              0.000000     0.000000   \n",
      "25     0.000000              0.000000              0.000000     0.000000   \n",
      "26     0.000000              0.000000              0.000000     0.000000   \n",
      "27     0.000000              0.000000              0.000000     0.000000   \n",
      "28     0.000000              0.000000              0.000000     0.000000   \n",
      "29     0.000000              0.000000              0.000000     0.000000   \n",
      "30     0.000000              0.000000              0.000000     0.000000   \n",
      "31     0.000000              0.000000              0.000000     0.000000   \n",
      "32     0.000000              0.000000              0.000000     0.000000   \n",
      "33     0.000000              0.000000              0.000000     0.000000   \n",
      "34     0.000000              0.000000              0.000000     0.000000   \n",
      "35     0.000000              0.000000              0.000000     0.000000   \n",
      "\n",
      "    6hr_mov_std  Hour  Minute  \n",
      "6      0.280556  17.0    40.0  \n",
      "7      0.269853  17.0    45.0  \n",
      "8      0.258547  17.0    50.0  \n",
      "9      0.245877  17.0    55.0  \n",
      "10     0.233800  18.0     0.0  \n",
      "11     0.222545  18.0     5.0  \n",
      "12     0.000000  18.0    10.0  \n",
      "13     0.000000  18.0    15.0  \n",
      "14     0.000000  18.0    20.0  \n",
      "15     0.000000  18.0    25.0  \n",
      "16     0.000000  18.0    30.0  \n",
      "17     0.000000  18.0    35.0  \n",
      "18     0.000000  18.0    40.0  \n",
      "19     0.000000  18.0    45.0  \n",
      "20     0.000000  18.0    50.0  \n",
      "21     0.000000  18.0    55.0  \n",
      "22     0.000000  19.0     0.0  \n",
      "23     0.000000  19.0     5.0  \n",
      "24     0.000000  19.0    10.0  \n",
      "25     0.000000  19.0    15.0  \n",
      "26     0.000000  19.0    20.0  \n",
      "27     0.000000  19.0    25.0  \n",
      "28     0.000000  19.0    30.0  \n",
      "29     0.000000  19.0    35.0  \n",
      "30     0.000000  19.0    40.0  \n",
      "31     0.000000  19.0    45.0  \n",
      "32     0.000000  19.0    50.0  \n",
      "33     0.000000  19.0    55.0  \n",
      "34     0.000000  20.0     0.0  \n",
      "35     0.000000  20.0     5.0  \n",
      "\n",
      " Target Shape: (24, 1)\n",
      "    GlucoseValue\n",
      "19      1.196654\n",
      "20      1.153962\n",
      "21      1.097039\n",
      "22      1.040116\n",
      "23      0.954732\n"
     ]
    }
   ],
   "source": [
    "encoder_file = get_first_file(encoder_dir)\n",
    "decoder_file = get_first_file(decoder_dir)\n",
    "target_file = get_first_file(target_dir)\n",
    "\n",
    "encoder_tensor = torch.load(encoder_file)\n",
    "decoder_tensor = torch.load(decoder_file)\n",
    "target_tensor = torch.load(target_file)\n",
    "\n",
    "encoder_df = pd.DataFrame(encoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "decoder_df = pd.DataFrame(decoder_tensor.numpy(), columns=[\"GlucoseValue\",\"5min_change\", \"30min_change\" ,\"1hr_change\",\"1hr_mov_avg\",\"1hr_mov_std\",\"1hr_largest_increase\",\"1hr_largest_decrease\",\"6hr_mov_avg\",\"6hr_mov_std\",\"Hour\", \"Minute\"])\n",
    "target_df = pd.DataFrame(target_tensor.numpy(), columns=[\"GlucoseValue\"])\n",
    "\n",
    "print(f\"\\n Encoder Shape: {encoder_df.shape}\")\n",
    "print(encoder_df.tail())\n",
    "print(f\"\\n Decoder Shape: {decoder_df.shape}\")\n",
    "print(decoder_df.tail(30))\n",
    "print(f\"\\n Target Shape: {target_df.shape}\")\n",
    "print(target_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#CONTENTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
